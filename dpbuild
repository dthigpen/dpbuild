#!/usr/bin/env python3

from __future__ import annotations

import argparse
import filecmp
from itertools import chain
from pathlib import Path, PurePath
from dataclasses import dataclass, field
import json
import shutil
import tempfile
import re
import os

LOAD_TAG_PATH = Path('data/load/tags/functions/load.json')

@dataclass
class Datapack:
    path: Path
    dependencies: list = field(default_factory=list)

    def __str__(self):
        return Datapack.__recursive_str(self)

    @staticmethod
    def __recursive_str(pack, output='', indent=0):
        indent_str = '  ' * indent
        pack_str = f'Path: {pack.path}'
        if pack.dependencies:
            pack_str += '\nDependencies:'
            for dep in pack.dependencies:
                pack_str = Datapack.__recursive_str(dep, pack_str + '\n', indent + 2)
        indented = '\n'.join(indent_str + line for line in pack_str.split('\n'))
        output += indented
        return output


def get_datapacks_in_dir(datapack_parent_dir: Path) -> list[Path]:
    datapacks = []
    if datapack_parent_dir.is_dir():
        for subdir in (d for d in datapack_parent_dir.iterdir() if d.is_dir()):
            try:
                datapacks.append(valid_datapack_path(str(subdir)))
            except:
                continue
    return datapacks

def get_sibling_datapack_paths(datapack_paths: list[Path]):
    parents = set()
    siblings = set(datapack_paths)
    for path in datapack_paths:
        parent = path.parent
        if parent not in parents:
            parents.add(parent)
            for sibling in [p for p in parent.iterdir() if p.is_dir()]:
                try:
                    valid_datapack_path(sibling)
                    siblings.add(sibling)
                except:
                    pass # TODO do better
    siblings.remove(datapack_paths[0])
    return siblings

def get_lantern_load_tag_functions(datapack_path: str):
    with open(datapack_path / LOAD_TAG_PATH, 'r') as load_file:
        return json.load(load_file)['values']

def detect_datapack_path_from_funct(load_funct: str, datapack_paths: list[Path]) -> Path:
    is_tag = load_funct.startswith('#')
    function_or_tag_dir = 'tags/functions' if is_tag else 'functions'
    file_ext = '.json' if is_tag else '.mcfunction'
    
    if is_tag:
        load_funct = load_funct
    namespace = load_funct[1 if is_tag else 0:load_funct.find(':')]
    load_file = load_funct[load_funct.find(':') + 1:] + file_ext
    for datapack_path in datapack_paths:
        if load_funct == get_lantern_load_tag_functions(datapack_path)[-1]:
            load_file_path = datapack_path / 'data' / namespace / function_or_tag_dir / load_file
            if load_file_path.is_file():
                return datapack_path
    print(f'Warning: Failed to find datapack matching load function {load_funct}')
    return None

def resolve_datapack(datapack_path: Path, all_datapack_paths: list[Path]) -> Datapack:
    datapack = Datapack(path=datapack_path)
    load_functions = get_lantern_load_tag_functions(datapack_path)
    if load_functions:
        # Pop last since its own load function
        # TODO only pop if last funct is in this datapack
        load_functions.pop()
        dep_datapacks = []
        for load_func in load_functions:
            dep_pack_path = detect_datapack_path_from_funct(load_func, all_datapack_paths)
            if dep_pack_path:
                dep_datapacks.append(resolve_datapack(dep_pack_path, all_datapack_paths)) 
        datapack.dependencies = dep_datapacks
    return datapack

def datapacks_at_path(path_str: str) -> list[Path]:
    datapacks = []
    msg = ""
    try:
        datapacks.append(valid_datapack_path(path_str))
    except Exception as e:
        msg = str(e)
        temp_path = Path(path_str)
        datapacks = get_datapacks_in_dir(temp_path)
    
    if not datapacks:
        raise argparse.ArgumentTypeError(f'Path is not a datapack or directory containing datapacks. {msg}')
    
    return datapacks


def valid_datapack_path(path_str: str) -> Path:
    path = Path(path_str)
    if not path.is_dir():
        raise argparse.ArgumentTypeError(f'Path to datapack does not exist: {path}')
    
    mc_meta_file = path / 'pack.mcmeta'
    if not mc_meta_file.is_file():
        raise argparse.ArgumentTypeError(f'Datapack does not have a pack.mcmeta file: {mc_meta_file}')
    
    lantern_load_tag = path / LOAD_TAG_PATH
    if not lantern_load_tag.is_file():
        raise argparse.ArgumentTypeError(f'Datapack does not have Lantern Load tag: {lantern_load_tag}')
    return path

def valid_dir(path_str: str) -> Path:
    path = Path(path_str)
    if not path.is_dir():
        raise argparse.ArgumentTypeError(f'Invalid directory: {path}')
    return path


def ignore_patterns(patterns: list[str]):
    def get_ignored(dir, filenames):
        dir_path = Path(dir)
        results = []
        for patt in patterns:
            for f in filenames:
                path = str(dir_path / f)
                if re.match(patt, path):
                    results.append(f)
        return results
    return get_ignored

def copy_datapack_files(datapack: Datapack, dest_data_dir: Path, file_ignore_patterns: list):
    src_data_dir = datapack.path / 'data'
    shutil.copytree(src_data_dir, dest_data_dir, ignore=ignore_patterns(file_ignore_patterns), dirs_exist_ok=True)
    for dep in datapack.dependencies:
        copy_datapack_files(dep, dest_data_dir, file_ignore_patterns)

def bundle_in_dest(datapack: Datapack, destination: Path, zip_up, release, no_dep_tests):
    main_pack_ignores = []
    ignore_tests = r'.+/functions/test(/.*)?'
    ignore_lantern_load = r'.+/data/load(/.*)?'
    ignore_minecraft_tags = r'.+/data/minecraft/tags(/.*)?'
    dependency_ignores = [ignore_lantern_load,ignore_minecraft_tags]
    if release:
        main_pack_ignores = [ignore_tests]
        dependency_ignores += [ignore_tests]
    
    if no_dep_tests:
        dependency_ignores += [ignore_tests]

    with tempfile.TemporaryDirectory() as tmpdir:
        src_datapack_path = datapack.path
        datapack_name = src_datapack_path.name
        dest_datapack_path = destination / datapack_name
        tmp_datapack_path = Path(tmpdir) / datapack_name
        # copy base datapack
        shutil.copytree(src_datapack_path, tmp_datapack_path,ignore=ignore_patterns(main_pack_ignores), dirs_exist_ok=True)
        # copy dependencies
        for dep in datapack.dependencies:
            copy_datapack_files(dep, tmp_datapack_path / 'data', dependency_ignores)        
        
        print(f'Building datapack at {dest_datapack_path}')
        if zip_up or release:
            zip_path = shutil.make_archive(datapack_name, 'zip', tmp_datapack_path)
            tmp_datapack_path = zip_path
            dest_datapack_path = destination / Path(zip_path).name
        
        if dest_datapack_path.exists():
            print(f'Removing existing pack..')
            if dest_datapack_path.is_dir():
                shutil.rmtree(dest_datapack_path)
            elif dest_datapack_path.is_file():
                os.remove(dest_datapack_path)
        shutil.move(tmp_datapack_path, dest_datapack_path)

        print('Done')

def move_changed_files(source_path: Path, dest_path: Path):
    
    # if the dest does not exist or is a different type than the source, copy over
    if not dest_path.exists() or (source_path.is_file() and dest_path.is_dir()) or (source_path.is_dir() and dest_path.is_file()):
        print(f'copy {source_path.name} to {dest_path}')
        if dest_path.is_dir():
            shutil.rmtree(dest_path)
        elif dest_path.is_file():
            os.remove(dest_path)
        shutil.move(source_path, dest_path)

    elif source_path.is_dir():
        for f in source_path.iterdir():
            dest_file = dest_path / f.name
            move_changed_files(f, dest_file)
        # TODO handle dir
    elif source_path.is_file():
        is_match = filecmp.cmp(source_path, dest_path, shallow=False)
        print(f'{source_path}, {dest_path}: {"NO CHANGES" if is_match else "CHANGED"}')
        if not is_match:
            shutil.copy2(source_path, dest_path)
    elif not source_path.exists():
        raise ValueError(f'Source path {source_path} does not exist!')


def get_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description='A tool to bundle packs with different namespaces. Requires each datapack to implement Lantern Load.')
    parser.add_argument('datapacks', nargs='*', type=datapacks_at_path, help='Datapack(s) to bundle. Only need to provide the top level datapack unless --strict is used.')
    parser.add_argument('--zip', action='store_true', help='Compress the bundled datapack into a .zip file')
    parser.add_argument('--dest', type=Path, default='bundles', help='Destination directory to copy bundled datapacks')
    parser.add_argument('--release', action='store_true', help='Removes function/test paths and zips output')
    parser.add_argument('--strict', action='store_true', help='Only attempts to bundle using passed datapacks and not check parent folder for dependencies')
    parser.add_argument('--no-dep-tests', action='store_true', help='Only applicable when not in release mode. Removes test functions from bundled dependency packs.')
    return parser.parse_args()


def run(datapack_paths_lists: list[list[Path]], destination_path: list[Path], zip_up: bool=False, release: bool=False, strict: bool=False, no_dep_tests: bool=False):
    if not datapack_paths_lists:
        datapack_paths_lists.append([valid_datapack_path(os.getcwd())])
    
    # ensure that the first path is actually a datapack and not a datapack dir
    if len(datapack_paths_lists[0]) != 1:
        raise argparse.ArgumentTypeError('First datapack argument must be a specific datapack and not a datapack directory')
    
    flattened_datapacks = list(chain.from_iterable(datapack_paths_lists))
    all_datapacks = datapack_paths_lists if strict else get_sibling_datapack_paths(flattened_datapacks)
    datapack = resolve_datapack(flattened_datapacks[0], all_datapacks)
    destination_path.mkdir(parents=True, exist_ok=True)
    bundle_in_dest(datapack,destination_path, zip_up, release, no_dep_tests)

if __name__ == "__main__":
    try:
        args = get_args()
        run(args.datapacks, args.dest, zip_up=args.zip, release=args.release, no_dep_tests=args.no_dep_tests)
    except argparse.ArgumentTypeError as e:
        print(f'Argument error: {e}')